{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: http://odds.cs.stonybrook.edu/letter-recognition-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(filename='data/letter.mat'):\n",
    "    \"\"\"Return X and Y data from MATLAB data\n",
    "    Given a MATLAB file, returns the data stored in\n",
    "    variables X and Y in Pandas DataFrame format.\n",
    "    \n",
    "    Args:\n",
    "        filename(str): Name of the file\n",
    "\n",
    "    Returns:\n",
    "        x_col(object): Pandas DataFrame containing\n",
    "            values in variable X\n",
    "        y_col(object): Pandas DataFrame containing\n",
    "            values in variable Y\n",
    "    \"\"\"\n",
    "    x_col = scipy.io.loadmat(filename)['X']\n",
    "    y_col = scipy.io.loadmat(filename)['y']\n",
    "    \n",
    "    x_col = pd.DataFrame(x_col)\n",
    "    y_col = pd.DataFrame(y_col)\n",
    "    \n",
    "    return [x_col, y_col]\n",
    "\n",
    "\n",
    "def normalize_data(data):\n",
    "    \"\"\"Normalizes given data.\n",
    "    For a given Pandas DataFrame, uses the StandardScaler\n",
    "    implementation to fit to the data and normalize it.\n",
    "    \n",
    "    Args:\n",
    "        data(object): Pandas DataFrame containing numerical\n",
    "            data points to be normalized.\n",
    "\n",
    "    Returns:\n",
    "        norm_data(object): Normalized data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        norm_data = StandardScaler().fit_transform(data)\n",
    "        return norm_data\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(y_true, y_pred):\n",
    "    \"\"\"Get f1 score for outlier classification.\n",
    "    \n",
    "    Args:\n",
    "        y_true(list): Original labels\n",
    "        y_pred(list): New labels\n",
    "        \n",
    "    Returns:\n",
    "        float: F1-score for classification\n",
    "    \n",
    "    \"\"\"\n",
    "    return round(f1_score(y_true, y_pred),2)\n",
    "    \n",
    "def transform_predictions_dbscan(labels, y_col):\n",
    "    \"\"\"Provide labels in sklearn format.\n",
    "    Transforms the original labels and predictions\n",
    "    from the model in list formatted so that it can\n",
    "    be used with sklearn to calculate metrics.\n",
    "    \n",
    "    Args:\n",
    "        labels(list): Original labels from the\n",
    "            dataset\n",
    "        y_col(list): Labels predicted by the model\n",
    "    \n",
    "    Returns:\n",
    "        [list, list]: Two lists, one with the original\n",
    "            labels for the dataset, and one with the \n",
    "            predicted labels\n",
    "    \"\"\"\n",
    "    y_pred = [1 if x == -1 else 0 for x in labels]\n",
    "    y_true = list(y_col.to_numpy().reshape(1,-1)[0])\n",
    "    \n",
    "    return [y_true, y_pred]\n",
    "\n",
    "\n",
    "def transform_predictions_gmm(labels, y_col, threshold):\n",
    "    \"\"\"Provide labels in sklearn format.\n",
    "    Transforms the original labels and predictions\n",
    "    from the model in list formatted so that it can\n",
    "    be used with sklearn to calculate metrics.\n",
    "    \n",
    "    Args:\n",
    "        labels(list): Original labels from the\n",
    "            dataset\n",
    "        y_col(list): Labels predicted by the model\n",
    "    \n",
    "    Returns:\n",
    "        [list, list]: Two lists, one with the original\n",
    "            labels for the dataset, and one with the \n",
    "            predicted labels\n",
    "    \"\"\"\n",
    "    y_pred = [1 if x < threshold else 0 for x in labels]\n",
    "    y_true = list(y_col.to_numpy().reshape(1,-1)[0])\n",
    "    \n",
    "    return [y_true, y_pred]\n",
    "\n",
    "\n",
    "def create_dbscan_model(data, eps, min_samples):\n",
    "    \"\"\"Create an sklearn DBSCAN model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples);\n",
    "        model = dbscan.fit(data);\n",
    "        return model.labels_\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "def create_gmm_model(data, n_components, cv_type):\n",
    "    \"\"\"Create an sklearn Gaussian Mixture model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from sklearn.mixture import GaussianMixture\n",
    "        gmm = GaussianMixture(n_components=n_components,\n",
    "                                      covariance_type=cv_type);\n",
    "        gmm.fit(data);\n",
    "        return gmm.score_samples(x_col)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "\n",
    "def create_knn_model(data, contamination, n_neighbors):\n",
    "    \"\"\"Create an sklearn Gaussian Mixture model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from pyod.models.knn import KNN\n",
    "        knn = KNN(contamination=contamination, n_neighbors=n_neighbors)\n",
    "        knn.fit(x_col) \n",
    "        return knn.labels_\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score  0.33000\n",
      "Recall  0.91000\n",
      "Precision  0.20088\n"
     ]
    }
   ],
   "source": [
    "# Import data from file\n",
    "x_col, y_col = import_data(filename='data/letter.mat')\n",
    "# Standardize all columns in the data\n",
    "x_col = normalize_data(x_col)\n",
    "# Run DBSCAN to categorize the models\n",
    "labels = create_dbscan_model(x_col, 3, 4)\n",
    "# Get f1_score from sklearn\n",
    "[y_true, y_pred] = transform_predictions_dbscan(labels, y_col)\n",
    "score = get_f1_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred, average=None)[1]\n",
    "precision = precision_score(y_true, y_pred, average=None)[1]\n",
    "print(\"F1-score %8.5f\\nRecall %8.5f\\nPrecision %8.5f\" %(score, recall, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score  0.32000\n",
      "Recall  0.65000\n",
      "Precision  0.21036\n"
     ]
    }
   ],
   "source": [
    "# Import data from file\n",
    "x_col, y_col = import_data(filename='data/letter.mat')\n",
    "# Standardize all columns in the data\n",
    "x_col = normalize_data(x_col)\n",
    "# Run DBSCAN to categorize the models\n",
    "labels = create_gmm_model(x_col, 26, 'spherical')\n",
    "# Get f1_score from sklearn\n",
    "[y_true, y_pred] = transform_predictions_gmm(labels, y_col, -40)\n",
    "score = get_f1_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred, average=None)[1]\n",
    "precision = precision_score(y_true, y_pred, average=None)[1]\n",
    "print(\"F1-score %8.5f\\nRecall %8.5f\\nPrecision %8.5f\" %(score, recall, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score  0.40000\n",
      "Recall  0.52000\n",
      "Precision  0.32500\n"
     ]
    }
   ],
   "source": [
    "# Import data from file\n",
    "x_col, y_col = import_data(filename='data/letter.mat')\n",
    "# Standardize all columns in the data\n",
    "x_col = normalize_data(x_col)\n",
    "# Guessing 10% are outliers performs better\n",
    "y_pred = create_knn_model(x_col, 0.10, 5)\n",
    "score = get_f1_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred, average=None)[1]\n",
    "precision = precision_score(y_true, y_pred, average=None)[1]\n",
    "print(\"F1-score %8.5f\\nRecall %8.5f\\nPrecision %8.5f\" %(score, recall, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
